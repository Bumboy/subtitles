1
00:00:00,000 --> 00:00:01,240


2
00:00:01,240 --> 00:00:03,720
[SINGING] Your online
application's starting to fail,

3
00:00:03,720 --> 00:00:07,540
and it's crawling on the
network just as fast as a snail.

4
00:00:07,540 --> 00:00:10,690
We need advanced programming
starting from the top.

5
00:00:10,690 --> 00:00:12,985
Better write some code so
the world doesn't stop.

6
00:00:12,985 --> 00:00:15,922


7
00:00:15,922 --> 00:00:19,250
With the non-blocking
model, we will be just fine.

8
00:00:19,250 --> 00:00:22,490
Build some Google
Chromes, right on time.

9
00:00:22,490 --> 00:00:25,780
And if all you need to do is
write some JavaScript code,

10
00:00:25,780 --> 00:00:28,210
and use the real-time
web with Node.

11
00:00:28,210 --> 00:00:32,549


12
00:00:32,549 --> 00:00:34,800
You're watching Real
Time Web with Node.

13
00:00:34,800 --> 00:00:35,700
I'm Carlos Souza.

14
00:00:35,700 --> 00:00:38,910
And in this level, we're going
to be talking about streams.

15
00:00:38,910 --> 00:00:40,410
When we're writing
applications that

16
00:00:40,410 --> 00:00:43,590
depend a lot on network
access and accessing

17
00:00:43,590 --> 00:00:47,340
files on the disk, one thing
that we have to keep an eye out

18
00:00:47,340 --> 00:00:51,030
for is how the data is being
transferred back and forth.

19
00:00:51,030 --> 00:00:55,560
Lucky for us, this is where
Node.js really shines.

20
00:00:55,560 --> 00:00:58,320
For ultimate efficiency,
and especially when

21
00:00:58,320 --> 00:01:00,480
we're dealing with
large sized data that's

22
00:01:00,480 --> 00:01:02,490
being sent across
the wire, we need

23
00:01:02,490 --> 00:01:05,760
to be able to access
that data piece by piece,

24
00:01:05,760 --> 00:01:07,710
or chunk by chunk.

25
00:01:07,710 --> 00:01:10,530
When that happens, we can
start manipulating that data

26
00:01:10,530 --> 00:01:12,660
as soon as it arrives
in the server,

27
00:01:12,660 --> 00:01:16,590
and keep it from being held
into memory all at once.

28
00:01:16,590 --> 00:01:20,730
Streams are like channels, where
data can simply flow through.

29
00:01:20,730 --> 00:01:22,330
They can be of different types.

30
00:01:22,330 --> 00:01:23,830
We're going to be
looking at the two

31
00:01:23,830 --> 00:01:27,050
most common, readable
and writable streams.

32
00:01:27,050 --> 00:01:29,160
And the streams API
that we've covered here,

33
00:01:29,160 --> 00:01:36,320
is for Node version 0.10,
also known as streams2 API.

34
00:01:36,320 --> 00:01:38,370
Some of the code that
we've seen in the course

35
00:01:38,370 --> 00:01:41,280
has already involved
working with streams.

36
00:01:41,280 --> 00:01:44,840
The request object for
example, is a readable stream.

37
00:01:44,840 --> 00:01:48,030
And the response object
is a writable stream.

38
00:01:48,030 --> 00:01:51,360
We read data from the
request and we write data

39
00:01:51,360 --> 00:01:53,130
to the response.

40
00:01:53,130 --> 00:01:56,310
When we run this code, an issue
or request from the browser,

41
00:01:56,310 --> 00:01:59,460
our server responds with
the 200 status code,

42
00:01:59,460 --> 00:02:02,490
and writes Dog is
running to the stream.

43
00:02:02,490 --> 00:02:06,000
The browser automatically
receives that response.

44
00:02:06,000 --> 00:02:09,990
Then, we fire a set
timeout for five seconds.

45
00:02:09,990 --> 00:02:12,420
But the stream is
still kept open.

46
00:02:12,420 --> 00:02:14,490
The channel between the
server and the client

47
00:02:14,490 --> 00:02:16,380
is still good to receive data.

48
00:02:16,380 --> 00:02:18,870
So five seconds
later, we write again

49
00:02:18,870 --> 00:02:22,630
to this stream, this
time, dog is done.

50
00:02:22,630 --> 00:02:24,170
And finally, we close it.

51
00:02:24,170 --> 00:02:27,720


52
00:02:27,720 --> 00:02:29,940
We've seen how to
write to the response,

53
00:02:29,940 --> 00:02:33,360
but how might we read
from the request?

54
00:02:33,360 --> 00:02:36,240
As we've mentioned
before, the request object

55
00:02:36,240 --> 00:02:38,070
is a readable stream.

56
00:02:38,070 --> 00:02:41,010
And it also inherits
from EventEmitter.

57
00:02:41,010 --> 00:02:44,250
This is a great combination,
because the request object

58
00:02:44,250 --> 00:02:48,540
can then communicate with other
objects through firing events.

59
00:02:48,540 --> 00:02:51,000
The events fired
are readable, which

60
00:02:51,000 --> 00:02:54,510
is fired when data is
ready to be consumed,

61
00:02:54,510 --> 00:02:57,360
and end which is
fired the client

62
00:02:57,360 --> 00:02:59,550
is done sending all the data.

63
00:02:59,550 --> 00:03:02,070
Now, let's write some code
where we print to the console

64
00:03:02,070 --> 00:03:04,680
the data that we received
from the request.

65
00:03:04,680 --> 00:03:06,510
So inside of our
request handler,

66
00:03:06,510 --> 00:03:09,660
we start by responding
with a 200 status code,

67
00:03:09,660 --> 00:03:12,960
then we'll listen to the
readable event on the request

68
00:03:12,960 --> 00:03:14,070
object.

69
00:03:14,070 --> 00:03:17,280
Inside of that, we
declare a chunk variable.

70
00:03:17,280 --> 00:03:19,650
Inside of the while loop,
we're going to read out

71
00:03:19,650 --> 00:03:22,000
a chunk from the request.

72
00:03:22,000 --> 00:03:25,450
And if it's not new, we'll
print it to the console.

73
00:03:25,450 --> 00:03:27,210
We have to call the
toString function,

74
00:03:27,210 --> 00:03:29,790
because the chunks we
get, they are buffers.

75
00:03:29,790 --> 00:03:32,870
So we might be dealing
with binary data here.

76
00:03:32,870 --> 00:03:35,470
Finally, we'll listen
to the end event.

77
00:03:35,470 --> 00:03:38,760
And when that event is fired,
we just finish the response.

78
00:03:38,760 --> 00:03:41,550
With this code, we're printing
to the console the data

79
00:03:41,550 --> 00:03:43,860
that we get from the client.

80
00:03:43,860 --> 00:03:46,770
How might we change this
so that we echo back

81
00:03:46,770 --> 00:03:50,430
to the client, the data
that we get on the request?

82
00:03:50,430 --> 00:03:52,774
All we have to do
is change one line.

83
00:03:52,774 --> 00:03:56,410


84
00:03:56,410 --> 00:03:58,950
In this case, instead
of console.log,

85
00:03:58,950 --> 00:04:01,300
we call response.write, here.

86
00:04:01,300 --> 00:04:04,170
Notice that we don't have to
call the toString function.

87
00:04:04,170 --> 00:04:07,710
response.write does that
behind the scenes for us.

88
00:04:07,710 --> 00:04:11,220
When all we need to do is
write to a writable stream

89
00:04:11,220 --> 00:04:13,950
as soon as we read from
a readable stream, which

90
00:04:13,950 --> 00:04:15,970
is exactly what
we're doing here,

91
00:04:15,970 --> 00:04:18,360
Node actually offers
a helper method

92
00:04:18,360 --> 00:04:22,530
that we can use to pipe these
two operations together.

93
00:04:22,530 --> 00:04:24,600
This method is called pipe.

94
00:04:24,600 --> 00:04:27,360
pipe handles all of the
events listening and chunk

95
00:04:27,360 --> 00:04:29,370
reading behind the scenes.

96
00:04:29,370 --> 00:04:35,130
So we can replace all of
this code with this one line.

97
00:04:35,130 --> 00:04:38,040
Now, when you were
uncurl from the terminal

98
00:04:38,040 --> 00:04:40,770
and send in the
string, 'hello', we

99
00:04:40,770 --> 00:04:43,680
can see that string
being sent back.

100
00:04:43,680 --> 00:04:45,810
In case you're used
to the Unix syntax,

101
00:04:45,810 --> 00:04:49,200
then you might remember pipe
from the command line, which

102
00:04:49,200 --> 00:04:52,230
streams the output
of one operation

103
00:04:52,230 --> 00:04:54,510
to the input of the next one.

104
00:04:54,510 --> 00:04:57,330
Whenever you can,
prefer using pipe

105
00:04:57,330 --> 00:04:59,220
over listening to
the readable event

106
00:04:59,220 --> 00:05:01,440
and manually reading the chunks.

107
00:05:01,440 --> 00:05:03,870
This can help protect
your application

108
00:05:03,870 --> 00:05:07,320
from future breaking changes
to the stream's API, which

109
00:05:07,320 --> 00:05:10,980
is still not stable.

110
00:05:10,980 --> 00:05:14,790
Remember that Node itself
hasn't reached 1.0 yet.

111
00:05:14,790 --> 00:05:18,330
So it's always good to check
whether a specific API that we

112
00:05:18,330 --> 00:05:20,590
want to use is stable or not.

113
00:05:20,590 --> 00:05:23,070
And we can do that
looking at the docs.

114
00:05:23,070 --> 00:05:26,640
Each core module has a
stability score next to it.

115
00:05:26,640 --> 00:05:30,120
We can see that the file system
module is considered stable

116
00:05:30,120 --> 00:05:32,100
with a score of three.

117
00:05:32,100 --> 00:05:36,330
This means that no major changes
are expected anytime soon.

118
00:05:36,330 --> 00:05:38,820
On the other hand,
the streams module

119
00:05:38,820 --> 00:05:42,580
is still unstable
with a score of 2.

120
00:05:42,580 --> 00:05:46,720
This means that changes to
the API are still possible.

121
00:05:46,720 --> 00:05:49,490
So next time a new
version of Node comes out,

122
00:05:49,490 --> 00:05:52,710
it's important to check
for any changes on streams

123
00:05:52,710 --> 00:05:56,550
or any other unstable API
your Node application might

124
00:05:56,550 --> 00:05:59,110
be using.

125
00:05:59,110 --> 00:06:02,040
Let's go over another
example of using streams.

126
00:06:02,040 --> 00:06:04,080
This time, we're going
to read the contents

127
00:06:04,080 --> 00:06:08,830
from a file in the file system
and stream it to another file.

128
00:06:08,830 --> 00:06:11,640
So first, we require
the file system module,

129
00:06:11,640 --> 00:06:15,090
then we create a read stream
from the original file,

130
00:06:15,090 --> 00:06:19,680
readme.md, and store that
to the file variable.

131
00:06:19,680 --> 00:06:23,760
Then, we create a write stream
to the destination file,

132
00:06:23,760 --> 00:06:28,680
readme_copy.md, and store
that on the new file variable.

133
00:06:28,680 --> 00:06:31,920
All we have to do
is call file.pipe

134
00:06:31,920 --> 00:06:34,230
passing in the new file.

135
00:06:34,230 --> 00:06:37,530
Stream is so powerful,
and yet, so simple

136
00:06:37,530 --> 00:06:39,750
to use with a pipe
function, that there's

137
00:06:39,750 --> 00:06:42,940
third party libraries
that heavily depend on it.

138
00:06:42,940 --> 00:06:45,960
One example is the
Gulp build system.

139
00:06:45,960 --> 00:06:50,040
gulp exposes the pipe
function as its public API

140
00:06:50,040 --> 00:06:52,140
so you can do all
sorts of manipulation

141
00:06:52,140 --> 00:06:55,520
on assets with very
few lines of code.

142
00:06:55,520 --> 00:06:57,510
I suggest you check
out gulp's website

143
00:06:57,510 --> 00:07:01,800
to look at some examples of
using streams in the wild.

144
00:07:01,800 --> 00:07:05,430
We can pipe any read stream
into any write stream.

145
00:07:05,430 --> 00:07:07,440
So let's combine
the two examples

146
00:07:07,440 --> 00:07:11,140
so we can read from the
request and pipe it to a file.

147
00:07:11,140 --> 00:07:13,760
So we'll keep our
write stream as is.

148
00:07:13,760 --> 00:07:15,790
But instead of
reading from a file,

149
00:07:15,790 --> 00:07:17,690
we're going to read
from their requests,

150
00:07:17,690 --> 00:07:19,920
calling request.pipe,
and pipe being

151
00:07:19,920 --> 00:07:22,500
the content to the new file.

152
00:07:22,500 --> 00:07:25,520
Lastly, we'll listen
to the end event

153
00:07:25,520 --> 00:07:28,170
and close the
response, responding

154
00:07:28,170 --> 00:07:30,540
with an uploaded stream.

155
00:07:30,540 --> 00:07:32,880
Now, when we run
this from our client,

156
00:07:32,880 --> 00:07:37,500
we call curl with a dash dash
upload-file option passing

157
00:07:37,500 --> 00:07:39,750
in a file as an argument.

158
00:07:39,750 --> 00:07:41,407
And then we can see
the response back.

159
00:07:41,407 --> 00:07:44,110


160
00:07:44,110 --> 00:07:46,590
So let's take a moment to
visualize what's going on here,

161
00:07:46,590 --> 00:07:50,190
because it's pretty amazing
that Node supports this.

162
00:07:50,190 --> 00:07:52,830
So we're streaming
pieces of the file

163
00:07:52,830 --> 00:07:55,620
from the client to the server.

164
00:07:55,620 --> 00:07:59,370
And the server is streaming
those pieces to disk

165
00:07:59,370 --> 00:08:01,880
as they are being
read from the request.

166
00:08:01,880 --> 00:08:03,570
At no point in
time is the server

167
00:08:03,570 --> 00:08:06,740
holding the entire
file in memory at once.

168
00:08:06,740 --> 00:08:09,060
It's all just
flowing continuously.

169
00:08:09,060 --> 00:08:12,960
And due to Node's nature,
it's all nonblocking.

170
00:08:12,960 --> 00:08:17,000
So if we try to upload two files
at the same time to the server,

171
00:08:17,000 --> 00:08:19,758
we can see that our node server
can handle them simultaneously.

172
00:08:19,758 --> 00:08:23,820


173
00:08:23,820 --> 00:08:27,090
One of the reasons that
Ryan Dahl created Node.js

174
00:08:27,090 --> 00:08:29,700
was to deal with file uploads.

175
00:08:29,700 --> 00:08:31,400
If you've done enough
web development,

176
00:08:31,400 --> 00:08:33,720
then you're probably
familiar with the whole drama

177
00:08:33,720 --> 00:08:37,440
that goes around implementing
file uploads correctly.

178
00:08:37,440 --> 00:08:39,559
What a lot of web
apps will try to do

179
00:08:39,559 --> 00:08:42,870
is to load the entire file
into memory before writing it

180
00:08:42,870 --> 00:08:46,380
to disk, which can cause all
sorts of issues on the server

181
00:08:46,380 --> 00:08:49,920
side and affect all the other
users of the same web app.

182
00:08:49,920 --> 00:08:53,010
And it's also tricky to be
able to provide the file

183
00:08:53,010 --> 00:08:57,030
progress to the clients as
the file is being uploaded.

184
00:08:57,030 --> 00:09:01,060
In Node.js, we can actually
do this quite simple.

185
00:09:01,060 --> 00:09:03,600
So let's look at how we
can implement our own file

186
00:09:03,600 --> 00:09:06,260
upload with progress.

187
00:09:06,260 --> 00:09:09,090
So this is what our
uploader will look like.

188
00:09:09,090 --> 00:09:12,800
We need to be able to issue
a request passing in a file,

189
00:09:12,800 --> 00:09:14,940
either from the command
line using curl,

190
00:09:14,940 --> 00:09:16,880
or from the browser.

191
00:09:16,880 --> 00:09:21,450
And then, receive the progress
as the file is being uploaded.

192
00:09:21,450 --> 00:09:25,920
To implement this, all we need
is the HTTP module and the File

193
00:09:25,920 --> 00:09:27,810
System module,
which you've already

194
00:09:27,810 --> 00:09:31,920
been using from our
previous examples.

195
00:09:31,920 --> 00:09:35,850
So we'll start with our upload
code, which we already created.

196
00:09:35,850 --> 00:09:39,120
Then, we need to know what the
entire size of the file is.

197
00:09:39,120 --> 00:09:41,400
And we'll do that by
reading the content length

198
00:09:41,400 --> 00:09:43,310
header from the request.

199
00:09:43,310 --> 00:09:46,030
We're going to store it
on the filebytes variable.

200
00:09:46,030 --> 00:09:48,000
We'll create the
upload bytes variable

201
00:09:48,000 --> 00:09:50,700
to keep track of how
many bytes were uploaded,

202
00:09:50,700 --> 00:09:53,320
and we'll initialize it to zero.

203
00:09:53,320 --> 00:09:55,530
Then, listening to
the readable event,

204
00:09:55,530 --> 00:10:00,150
we'll loop through and read each
of the chunks from the request.

205
00:10:00,150 --> 00:10:02,970
Inside of the while loop, we'll
increment the uploaded bytes

206
00:10:02,970 --> 00:10:06,150
variable with the
length of each chunk.

207
00:10:06,150 --> 00:10:10,800
Then, we calculate progress by
dividing uploaded bytes by file

208
00:10:10,800 --> 00:10:13,410
bytes, and multiply it by 100.

209
00:10:13,410 --> 00:10:15,360
Then, we send the progress
back to the client

210
00:10:15,360 --> 00:10:17,790
using the
response.write function.

211
00:10:17,790 --> 00:10:22,070
We use parseInt to round
the progress to an integer.

212
00:10:22,070 --> 00:10:24,150
Down at the bottom,
Pipe is still

213
00:10:24,150 --> 00:10:26,690
taking care of the
actual upload for us.

214
00:10:26,690 --> 00:10:29,700
And the only reason why are
we using the readable event

215
00:10:29,700 --> 00:10:35,010
is so that we can keep track
of the current progress.

216
00:10:35,010 --> 00:10:39,050
Now, when we run our
code and upload our file,

217
00:10:39,050 --> 00:10:41,547
we can see the progress.

218
00:10:41,547 --> 00:10:42,047
Nice.

219
00:10:42,047 --> 00:10:44,910


220
00:10:44,910 --> 00:10:46,350
So that's it for this level.

221
00:10:46,350 --> 00:10:48,430
Have fun with the challenges.

222
00:10:48,430 --> 00:10:50,390
